# 数据结构

## 二叉树

二叉树（Binary Tree）是指每个节点最多只有两个分支的树结构

### 二叉搜索树

一棵空树或者满足以下性质的二叉树被称之为二叉查找树（Binary Search Tree）也被称为二叉搜索树、有序二叉树（Ordered Binary Tree）或排序二叉树（Sorted Binary Tree）等。

(1)如果任意节点的左子树不为空，并且左子树上所有节点的值均小于它的根节点的值；

(2)如果任意节点的右子树不为空，并且右子树上所有节点的值均大于或等于它的根节点的值；

(3)任意节点的左、右子树分别为二叉查找树。

### 平衡树(AVL树)

所谓的平衡树是指一种改进的二叉查找树，顾名思义平衡树就是将二叉查找树平衡均匀地分布，这样的好处就是可以减少二叉查找树的深度。

一般情况下二叉查找树的查询复杂度取决于目标节点到树根的距离（即深度），当节点的深度普遍较大时，查询的平均复杂度就会上升，因此为了实现更高效的查询就有了平衡树。

非平衡二叉树(左)和平衡二叉树(右)如下图所示：

![14](.\img\14.png)

### 红黑树

红黑树除了具备二叉查找树的基本特性之外，还具备以下特性：

(1)    节点是红色或黑色；

(2)    根节点是黑色；

(3)    所有叶子都是黑色的空节点（NIL 节点）；

(4)    每个红色节点必须有两个黑色的子节点，也就是说从每个叶子到根的所有路径上，不能有两个连续的红色节点；

(5)    从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑色节点。

红黑树在查找方面和AVL树操作几乎相同。但是在插入和删除操作上，AVL树每次插入删除会进行大量的平衡度计算，红黑树是牺牲了严格的高度平衡的优越条件为代价，它只要求部分地达到平衡要求，结合变色，降低了对旋转的要求，从而提高了性能.

它的添加、删除以及查询数据的时间复杂度为 O(logn)。

![15](.\img\15.png)

## 哈希表--数组+链表

```c++
/*
 * @Author: your name
 * @Date: 2022-03-07 19:50:48
 * @LastEditTime: 2022-03-23 22:44:33
 * @LastEditors: Please set LastEditors
 * @Description: 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
 * @FilePath: /myinterview/hash.h
 */

#include<utility>
#include<vector>
using namespace std;
template<typename K,typename V>
class hashnode{
public:
   // hashnode():_pair(make_pair(key,value)),next(nullptr){}
   // hashnode(K key,V value):_pair(make_pair(key,value)),next(nullptr){}
    hashnode(std::pair<K,V> _pair):_pair(_pair),next(nullptr){}
    std::pair<K,V>& getpair(){
        return _pair;
    }
    hashnode* getnext(){
        return next;
    }
    void setnext( hashnode*_next){
        next=_next;
    }
private:
    std::pair<K,V> _pair;
    hashnode* next;
    
};

template<typename K,typename V,typename hashfunc>
class hashtable{
public:
    hashtable():hash_pair(vector<hashnode<K,V>*>(10,nullptr)),hash(){};

    ~hashtable(){
        for(int i=0;i<hash_pair.size();i++){
             hashnode<K,V> *cursor=hash_pair[i];
             hashnode<K,V> *next=nullptr;
             while(cursor){
                 next=cursor->getnext();
                 delete cursor;
                 cursor=next;
             }
             hash_pair[i]=nullptr;

        }
    }

    void insert(std::pair<K,V> pair){
       hashnode<K,V>*ptr=search(pair.first);
       if(ptr==nullptr){
           hash_pair[gethash(pair.first)%10]=new hashnode<K,V>(pair);
       }else if(ptr->getpair().first!=pair.first){//找到的是prev，执行插入
           ptr->setnext(new hashnode<K,V>(pair));
       }else if(ptr->getpair().first==pair.first){//找到的是cursor，执行更新
           ptr->getpair().second=pair.second;
       }
            
    }

    int erase(K key){
         hashnode<K,V>*ptr=search(key);
         if(ptr==nullptr||ptr->getpair().first!=key)//没有节点等于key
            return 0;
         else{
                hashnode<K,V> *cursor=hash_pair[gethash(key)%10];
                hashnode<K,V> *prev=nullptr;
                while(cursor){
                    if(cursor->getpair().first==key){//返回key值相同节点;
                        break;
                        }
                    else
                        { //记录前节点;
                            prev=cursor;
                            cursor=cursor->getnext();
                            }
                }
                    prev->setnext(cursor->getnext());
                    delete cursor;
                    return 1;
            } 
        }
        
    V& operator[](K key){
        hashnode<K,V>*ptr= search(key); 
        if(ptr->getpair().first==key){
            return ptr->getpair().second;
        }else if(ptr==nullptr){
            hashnode<K,V>*tmp=new hashnode<K,V>({key,V()});
            hash_pair[gethash(key)%10]=tmp;
            return tmp->getpair().second;
        }else{
            hashnode<K,V>*tmp=new hashnode<K,V>({key,V()});
            ptr->setnext(tmp);
            return tmp->getpair().second;
        }
    }


private:
    vector<hashnode<K,V>*>hash_pair;
    hashfunc hash;

    int gethash(K key){
        return  hash(key);
    }

    hashnode<K,V>* search(K key){
         int index=gethash(key)%10;
         if(hash_pair[index]==nullptr)
            {
                return nullptr;
            }
        else{
            hashnode<K,V> *cursor=hash_pair[index];
            hashnode<K,V> *prev=nullptr;
            while(cursor){
                    if(cursor->getpair().first==key){//返回key值相同节点;
                        return cursor;
                        }
                    else
                        { //记录前节点;
                            prev=cursor;
                            cursor=cursor->getnext();
                            }
                }
                return prev;
        }       
    }
};
//哈希函数
class hashfunc{
public:
    int  operator()(int a){
        return a*114514;
    }
};
```



# Linux

```
查看CPU信息：
	ps：显示按照按照消耗CPU前10排序的进程
	top：任务、CPU状态、内存状态、各进程的状态监控
查看内存信息：
	ps
	top
	pmap：查看进程的内存状态，以及内存映射
查看磁盘IO信息
	iotop
	iostat
查看端口信息
	netstat
```





# 进程和线程、协程

进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；

进程一般由程序、数据集合和进程控制块三部分组成。

- 程序用于描述进程要完成的功能，是控制进程执行的指令集；
- 数据集合是程序在执行时所需要的数据和工作区；
- 程序控制块(Program Control Block，简称PCB)，包含进程的描述信息和控制信息，是进程存在的唯一标志。

在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。

后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程。

线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。

```
任务调度
	在一个进程中，当一个线程任务执行几毫秒后，会由操作系统的内核（负责管理各个任务）进行调度，通过硬件的计数器中断处理器，让该线程强制暂停并将该线程的寄存器放入内存中，通过查看线程列表决定接下来执行哪一个线程，并从内存中恢复该线程的寄存器，最后恢复该线程的执行，从而去执行下一个任务。
	上述过程中，任务执行的那一小段时间叫做时间片，任务正在执行时的状态叫运行状态，被暂停的线程任务状态叫做就绪状态，意为等待下一个属于它的时间片的到来。

  这种方式保证了每个线程轮流执行，由于CPU的执行效率非常高，时间片非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发(别觉得并发有多高深，它的实现很复杂，但它的概念很简单，就是一句话：多个任务同时执行)。多任务运行过程的示意图如下：
```

![image](.\img\29.png)

1.一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。

2.进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）

3.进程是资源分配的最小单位，线程是CPU调度的最小单位；

4.系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。

5.通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预

6.进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。

7.进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉

8.进程适应于多核、多机分布；线程适用于多核

## 线程池

一种线程的使用模式，线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代价。线程池不仅能够保证内核的充分利用，还能防止过分调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。

“管理一个任务队列，一个线程队列，然后每次取一个任务分配给一个线程去做，循环往复。

## 进程间通讯

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**

```
1.匿名管道通信
	半双工通信方式，数据单向流动，而且只能在具有亲缘关系的进程间使用，指父子进程
·父进程创建管道，得到两个⽂件描述符指向管道的两端
·父进程fork出子进程，⼦进程也有两个⽂件描述符指向同⼀管道。
·父进程关闭fd[0],子进程关闭fd[1]，即⽗进程关闭管道读端,⼦进程关闭管道写端（因为管道只支持单向通信）。
·⽗进程可以往管道⾥写,⼦进程可以从管道⾥读,管道是⽤环形队列实现的,数据从写端流⼊从读端流出,这样就实现了进程间通信。
2.高级管道通信
	将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。
3.有名管道通信
	有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
4.消息队列
 	消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
5.信号量通信
	信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6.信号
	信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
7.共享内存通信
	共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
8.套接字通信
	套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。
```



# 锁机制

互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒

读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。

RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。

1、互斥锁和读写锁区别：

互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

互斥锁和读写锁的区别：

1）读写锁区分读者和写者，而互斥锁不区分

2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

#多路复用

I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。

## select

![img](.\img\select.png)

用户首先将需要进行IO操作的socket添加到select中，然后阻塞等待select系统调用返回。当数据到达时，socket被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行。

从流程上来看，使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多了添加监视socket，以及调用select函数的额外操作，效率更差。但是，使用select以后最大的优势是用户可以在一个线程内同时处理多个socket的IO请求。用户可以注册多个socket，然后不断地调用select读取被激活的socket，即可达到在**同一个线程内同时处理多个IO请求的目的**。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。这是reactor设计模式的体现

![img](.\img\reactor.png)

```
select缺点
（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
（3）select支持的文件描述符数量太小了，默认是1024复制代码
```

## poll

poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构

```c++
int poll(struct pollfd *fds, nfds_t nfds, int timeout);


struct pollfd{
	int fd;			//文件描述符
	short events;	//等待的事件
	short revents;	//实际发生的事件
}

```

fd：每一个 pollfd 结构体指定了一个被监视的文件描述符，可以传递多个结构体，指示 poll() 监视多个文件描述符。

events：指定监测fd的事件（输入、输出、错误），每一个事件有多个取值，如下：

![poll](./img/poll.png)

revents：revents 域是文件描述符的操作结果事件，内核在调用返回时设置这个域。events 域中请求的任何事件都可能在 revents 域中返回.
注意：每个结构体的 events 域是由用户来设置，告诉内核我们关注的是什么，而 revents 域是返回时内核设置的，以说明对该描述符发生了什么事件
nfds：用来指定第一个参数数组元素个数
timeout：指定等待的毫秒数，无论 I/O 是否准备好，poll() 都会返回.

返回值：

成功时，poll() 返回结构体中 revents 域不为 0 的文件描述符个数；如果在超时前没有任何事件发生，poll()返回 0；

失败时，poll() 返回 -1，并设置 errno 为下列值之一：

EBADF：一个或多个结构体中指定的文件描述符无效。
EFAULT：fds 指针指向的地址超出进程的地址空间。
EINTR：请求的事件之前产生一个信号，调用可以重新发起。
EINVAL：nfds 参数超出 PLIMIT_NOFILE 值。
ENOMEM：可用内存不足，无法完成请求。

##epoll

epoll是一种I/O事件通知机制，是linux 内核实现IO多路复用的一个实现

通知机制，就是当事件发生的时候，则主动通知。通知机制的反面，就是轮询机制。

epoll的通俗解释是一种当文件描述符的内核缓冲区非空的时候，发出可读信号进行通知，当写缓冲区不满的时候，发出可写信号通知的机制

epoll的核心是3个API，核心数据结构是：1个红黑树和1个链表

![15](.\img\15.jpg)

**int epoll_create(int size)**

内核会产生一个epoll 实例数据结构并返回一个文件描述符，这个特殊的描述符就是epoll实例的句柄，后面的两个接口都以它为中心

**int epoll_ctl(int epfd， int op， int fd， struct epoll_event \*event)**

将被监听的描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改

**int epoll_wait(int epfd， struct epoll_event \*events， int maxevents， int timeout)**

阻塞等待注册的事件发生，返回事件的数目，并将触发的事件写入events数组中。

##select、poll、epoll

![img](.\img\COMPARE.PNG)

**1. 用户态将文件描述符传入内核的方式**

select：创建3个文件描述符集并拷贝到内核中，分别监听读、写、异常动作。这里受到单个进程可以打开的fd数量限制，默认是1024。

poll：将传入的struct pollfd结构体数组拷贝到内核中进行监听。

epoll：执行epoll_create会在内核的高速cache区中建立一颗红黑树以及就绪链表(该链表存储已经就绪的文件描述符)。接着用户执行的epoll_ctl函数添加文件描述符会在红黑树上增加相应的结点。

**2. 内核态检测文件描述符读写状态的方式**

select：采用轮询方式，遍历所有fd，最后返回一个描述符读写操作是否就绪的mask掩码，根据这个掩码给fd_set赋值。

poll：同样采用轮询方式，查询每个fd的状态，如果就绪则在等待队列中加入一项并继续遍历。

epoll：采用回调机制。在执行epoll_ctl的add操作时，不仅将文件描述符放到红黑树上，而且也注册了回调函数，内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数将文件描述符放在就绪链表中。

**3. 找到就绪的文件描述符并传递给用户态的方式**

select：将之前传入的fd_set拷贝传出到用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。

poll：将之前传入的fd数组拷贝传出用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。

epoll：epoll_wait只用观察就绪链表中有无数据即可，最后将链表的数据返回给数组并返回就绪的数量。内核将就绪的文件描述符放在传入的数组中，所以只用遍历依次处理即可。

**4. 重复监听的处理方式**

select：将新的监听文件描述符集合拷贝传入内核中，继续以上步骤。

poll：将新的struct pollfd结构体数组拷贝传入内核中，继续以上步骤。

epoll：无需重新构建红黑树，直接沿用已存在的即可。



# 内存

正文段：由CPU执行的机器指令部分，通常，正文段是可共享的，只读的，防止程序由于意外修改其指令

初始化数据段：简称为数据段，它包含了程序中需要明确赋初值的变量

未初始化数据段：也称为BSS段，在程序开始执行之前，内核将此段的数据初始化为0或空指针

栈：自动变量以及每次函数调用时所保存的信息。每次函数调用时，其返回地址以及调用者的环境信息都存放在栈中。最近被调用的函数在栈上自动为其分配存储空间。递归函数每次调用自身时，就会形成一个新的栈帧，因此一次函数调用实例中的变量集不会影响另一次函数调用实例中的变量

栈上边是命令行参数和进程的环境变量

堆：通常在堆中进行动态存储分配。历史惯例：堆位于未初始化数据段和栈之间

![12](.\img\12.png)

## 虚拟内存

计算机对内存分为物理内存与虚拟内存。物理内存就是计算机的实际内存大小，由 RAM 芯片组成的。虚拟内存则是虚拟出来的。

虚拟内存将用户逻辑内存与物理内存分开。这在现有物理内存有限的情况下，为程序员提供了巨大的虚拟内存。并由操作系统完成从[虚拟内存](https://so.csdn.net/so/search?q=虚拟内存&spm=1001.2101.3001.7020)的虚拟地址到真实内存地址或者磁盘空间之间的映射工作。除了将逻辑内存与物理内存分开外，虚拟内存允许文件和内存通过共享页而为多个进程所共享。这带来了以下好处：

1. 通过将共享对象映射到虚拟地址空间中，系统库可以为多个进程所共享。尽管每个进程都将库视为其虚拟地址空间的一部分，但是驻留在物理内存中的库的实际页可由所有进程共享（图 3）。通常，库按只读方式映射到与其链接的进程空间。
2. 类似地，虚拟内存允许进程共享内存。进程之间可以通过使用共享内存来进行通信。虚拟内存允许一个进程创建一个内存区域，以便与其他进程共享。共享这个内存区域的进程认为，它是其虚拟地址空间的一部分，而事实上这部分是共享的，如图 3 所示。
3. 当通过系统调用 fork() 创建进程时，可以共享页面，从而加快进程创建。

## 分页分段

```
分段的内存碎片太大，是计算中发展过程中尝试过的方案，现在的方案是内存分页，通过某种方式，将虚拟地址映射到物理地址，映射的关系是通过一张表实现的，也就是页表。
```

### 分段

![img](.\img\c++.jpg)

### 分页

分页机制的思想是:通过映射，可以使连续的线性地址与物理地址相关联，逻辑上连续的线性地址对应的物理地址可以不连续。 分页的作用 - 将线性地址转换为物理地址 - 用大小相同的页替换大小不同的段

![img](.\img\fenye.jpg)

## 虚拟内存



# 编译

## 静态库和动态库

gcc生成动态和静态库

```sh
gcc -static a.c -o a.o
ar rcs -o liba.a a.o   //生成 .o文件后用ar打包成静态库
ar t libtest.a  //查看库中包含的.o文件
```

```sh
gcc -shared -fPIC a.c -o libmyshare.so  //-fPIC生成位置无关代码，以供动态库使用
nm libmyshare.so //nm查看动态库里面的符号
gcc test.c   -L .  -lmyshare -o test   //test中引用动态库符号，使用extern ，引用库中不存在的，或static的符号会报错
./test //提示找不到库
ldd test//使用ldd命令查看库依赖，竟然找不到当前文件夹下的动态库，搜了一下，应该有两种方法：

一、可以把当前路径加入 /etc/ld.so.conf中然后运行ldconfig，或者以当前路径为参数运行ldconfig（要有root权限才行）。

二、把当前路径加入环境变量LD_LIBRARY_PATH中
export LD_LIBRARY_PATH=.:$LD_LIBRARY_PATH

当然，如果你觉得不会引起混乱的话，可以直接把该库拷入/lib,/usr/lib/等位置（无可避免，这样做也要有权限），这样链接器和加载器就都可以准确的找到该库了。


./test  运行成功
```



共享库的一个优点是，可以用库函数的新版本代替老版本而无需对该库的程序进行重新连接编译

- 静态库：链接步骤中，链接器将从库文件中取得代码，复制到可执行文件中，此种称为静态库。其特点是可执行文件中包含了库代码的一份完整拷贝；缺点就是被多次使用就会有多份冗余拷贝。即静态库中的指令都全部被直接包含在最终生成的 EXE 文件中了，有两个缺点1.对磁盘空间的浪费-如果生成多个exe文件，每个exe里都有静态库目标代码的拷贝2.多个程序调用静态库，在内存里有多个静态库的副本，浪费内存3.修改静态库后需要对程序重新编译
- 动态库：动态链接库是一个包含可由多个程序同时使用的代码和数据的库。动态链接提供了一种方法，使进程可以调用不属于其可执行代码的函数。只在第一次加载时进入内存，只且保存一份。函数的可执行代码位于一个 DLL （so）中，该 DLL （so）包含一个或多个已被编译、链接并与使用它们的进程分开存储的函数

关于windows下的动态库伴随一个lib文件

Windows下用VS创建DLL项目生成.dll文件时，*一般*会伴随生成一个.lib文件；使用这个.dll文件时，需要将伴随的.lib加进链接选项。事实上，这里的.lib文件中只包含简单的导出定义，实际的代码还是在.dll文件中。这里的.lib文件并非是上面提到的 静态库，而是动态链接库的**导入库**(Import Libary)。虽然共用扩展名，但它们的内容是完全不一样的。导入库只在链接的时候需要，程序运行的时候只需要.dll文件即可。此外，DLL项目中必须至少导出一个函数、变量或者类才会有.lib生成， 没有导出的话就不生成.lib文件。由于一般情况下DLL项目都是为了导出符号给别的项目用，所以才给人一种动态库总伴随着一个“静态库”文件的假象。

备注：LIB是编译时用到的，DLL是运行时用到的。如果要完成源代码的编译，需要LIB(其实直接使用win32 API 的Loadlibrary函数直接加载dll也是可以的);如果要使动态链接的程序运行起来，只需要DLL。

**动态库中的LIB**:该LIB包含了函数所在的DLL文件和文件中函数位置的信息（索引），函数实现代码由运行时加载在进程空间中的DLL提供。



## Linux库打桩机制

利用打桩机制，可以最总对某个特殊库函数的调用次数，验证和最总它的输入和输出值

给定一个需要大壮的目标函数，创建一个包装函数，函数原型和目标函数一样，欺骗系统调用此函数，然后在这个函数内调用目标函数

### 编译打桩

### 链接打桩

### 运行打桩

# exit，abort，return

![13](.\img\13.png)

